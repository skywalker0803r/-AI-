{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xPfzxJaQN39v3wE3dkdzQZmdEl3cPf-x",
      "authorship_tag": "ABX9TyOnQHDY8KcYc4+LNRvVBl0a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/-AI-/blob/main/api%E4%BD%BF%E7%94%A8%E7%AF%84%E4%BE%8B_%E5%BD%B1%E7%89%87%E7%89%88api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import requests\n",
        "# 設定 API 的 URL\n",
        "#可以ping 但不要太長ping 我怕免費額度爆掉\n",
        "url = \"https://mmpose-api-924124779607.us-central1.run.app/pose_video\"  # 替換為你的 API URL\n",
        "# 使用 with 開啟檔案並傳送\n",
        "with open('/content/pitch_0029.mp4', 'rb') as video_file:\n",
        "    # 以 multipart/form-data 格式上傳檔案\n",
        "    files = {'file': ('/content/pitch_0029.mp4', video_file, 'video/mp4')}\n",
        "    response = requests.post(url, files=files)\n",
        "# 查看回應內容\n",
        "print(response.json())\n",
        "response.json()['frames']"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z986JRbheKMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO 回傳的response.json() 丟到一個函數 計算出 所有需要的東西\n"
      ],
      "metadata": {
        "id": "jv39Ywc-3EoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response2features(response.json()):\n",
        "  #算算算一大堆 例如運動力學特徵\n",
        "  return"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tSN2Wdl-2OHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 測試用 執行這個CELL 會把 response.json() 渲染到原始影片上"
      ],
      "metadata": {
        "id": "0MZJJ_sK3TdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import base64\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "# 為了在 Colab 中顯示保存的影片\n",
        "from IPython.display import Video, display\n",
        "import os # 用於檢查檔案是否存在\n",
        "\n",
        "# COCO 關鍵點定義 (17 個點的順序)\n",
        "# 確保這個列表與您的 API 返回的關鍵點順序一致\n",
        "COCO_KEYPOINTS = [\n",
        "    \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\",\n",
        "    \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n",
        "    \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\", \"left_knee\",\n",
        "    \"right_knee\", \"left_ankle\", \"right_ankle\"\n",
        "]\n",
        "\n",
        "# COCO 骨架連接關係 (基於 COCO_KEYPOINTS 的索引)\n",
        "COCO_CONNECTIONS = [\n",
        "    (0, 1), (0, 2), (1, 3), (2, 4),  # 頭部和臉: 鼻子-左眼, 鼻子-右眼, 左眼-左耳, 右耳-右耳\n",
        "    (5, 6),  # 軀幹: 左肩-右肩\n",
        "    (5, 7), (7, 9),  # 左臂: 左肩-左肘, 左肘-左手腕\n",
        "    (6, 8), (8, 10), # 右臂: 右肩-右肘, 右肘-右手腕\n",
        "    (5, 11), (6, 12), (11, 12), # 軀幹和臀部: 左肩-左髖, 右肩-右髖, 左髖-右髖\n",
        "    (11, 13), (13, 15), # 左腿: 左髖-左膝, 左膝-左腳踝\n",
        "    (12, 14), (14, 16)  # 右腿: 右髖-右膝, 右膝-右腳踝\n",
        "]\n",
        "\n",
        "\n",
        "def draw_pose_on_frame(frame, predictions, min_score_thresh=0.5, point_radius=5, line_thickness=2):\n",
        "    \"\"\"\n",
        "    在單個影片幀上繪製姿態關鍵點和骨架。\n",
        "\n",
        "    Args:\n",
        "        frame (np.array): OpenCV 圖片幀 (BGR 格式)。\n",
        "        predictions (list): API 回應中針對該幀的 'predictions' 列表。\n",
        "                            預期格式: [{'keypoints': [[x, y], ...], 'keypoint_scores': [...], ...}]\n",
        "        min_score_thresh (float): 關鍵點顯示的最低置信度閾值。\n",
        "        point_radius (int): 關鍵點圓圈的半徑。\n",
        "        line_thickness (int): 骨架線條的粗細。\n",
        "\n",
        "    Returns:\n",
        "        np.array: 繪製了姿態的幀 (BGR 格式)。\n",
        "    \"\"\"\n",
        "    if not predictions:\n",
        "        return frame # 如果沒有偵測到姿態，直接返回原幀\n",
        "\n",
        "    # 針對每個偵測到的人繪製姿態\n",
        "    for person_prediction in predictions:\n",
        "        keypoints_coords = person_prediction.get('keypoints', [])\n",
        "        keypoint_scores = person_prediction.get('keypoint_scores', [])\n",
        "\n",
        "        if not keypoints_coords or not keypoint_scores:\n",
        "            continue\n",
        "\n",
        "        # 將關鍵點座標和分數打包成列表，方便後續處理\n",
        "        # 這裡的 keypoints_data 會是 [(x, y, score), (x, y, score), ...]\n",
        "        keypoints_data = []\n",
        "        for i, (x, y) in enumerate(keypoints_coords):\n",
        "            score = keypoint_scores[i] if i < len(keypoint_scores) else 0.0\n",
        "            keypoints_data.append((int(x), int(y), score)) # 轉換為整數像素座標\n",
        "\n",
        "        # 繪製關鍵點\n",
        "        for kp_idx, (x, y, score) in enumerate(keypoints_data):\n",
        "            if score > min_score_thresh:\n",
        "                # 關鍵點顏色 (B, G, R) - 例如，綠色\n",
        "                cv2.circle(frame, (x, y), point_radius, (0, 255, 0), -1)\n",
        "\n",
        "        # 繪製骨架連接\n",
        "        for connection in COCO_CONNECTIONS:\n",
        "            start_kp_idx = connection[0]\n",
        "            end_kp_idx = connection[1]\n",
        "\n",
        "            if start_kp_idx < len(keypoints_data) and end_kp_idx < len(keypoints_data):\n",
        "                x1, y1, s1 = keypoints_data[start_kp_idx]\n",
        "                x2, y2, s2 = keypoints_data[end_kp_idx]\n",
        "\n",
        "                if s1 > min_score_thresh and s2 > min_score_thresh:\n",
        "                    # 連線顏色 (B, G, R) - 例如，黃色\n",
        "                    cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 255), line_thickness)\n",
        "    return frame\n",
        "\n",
        "def render_video_with_pose(video_path: str, api_response_json: dict) -> tuple:\n",
        "    \"\"\"\n",
        "    將姿態偵測結果渲染到原始影片的每一幀上，並返回幀列表和影片的 FPS。\n",
        "\n",
        "    Args:\n",
        "        video_path (str): 原始影片文件的路徑。\n",
        "        api_response_json (dict): 從 API 獲得的完整 JSON 回應。\n",
        "\n",
        "    Returns:\n",
        "        tuple: (list, float) 包含每個渲染後幀的 NumPy 圖片陣列 (RGB 格式)，\n",
        "               以及影片的幀率 (FPS)。如果影片無法讀取，則返回 ([], 0.0)。\n",
        "    \"\"\"\n",
        "    rendered_frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {video_path}\")\n",
        "        return [], 0.0\n",
        "\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) # 獲取影片的 FPS\n",
        "    print(f\"Video opened: {video_path}, Resolution: {frame_width}x{frame_height}, Frames: {total_frames}, FPS: {fps}\")\n",
        "\n",
        "\n",
        "    api_frames_data = {frame_data['frame_idx']: frame_data for frame_data in api_response_json.get('frames', [])}\n",
        "\n",
        "    current_frame_idx = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break # 影片讀取結束\n",
        "\n",
        "        # 從 API 回應中獲取當前幀的姿態數據\n",
        "        predictions_raw = api_frames_data.get(current_frame_idx, {}).get('predictions', [])\n",
        "\n",
        "        # *** 修正這裡：根據您提供的數據結構，predictions 是一個包含一個列表的列表 ***\n",
        "        # 例如: [[{'keypoints': ...}, {'keypoints': ...}]]\n",
        "        # 我們需要取出內層的列表\n",
        "        predictions_for_current_frame = []\n",
        "        if predictions_raw and isinstance(predictions_raw, list):\n",
        "            if predictions_raw and isinstance(predictions_raw[0], list):\n",
        "                predictions_for_current_frame = predictions_raw[0]\n",
        "            elif predictions_raw and isinstance(predictions_raw[0], dict):\n",
        "                # 如果未來 API 結構改變，直接就是字典列表，這裡也可以兼容\n",
        "                predictions_for_current_frame = predictions_raw\n",
        "\n",
        "        # 在幀上繪製姿態\n",
        "        rendered_frame = draw_pose_on_frame(\n",
        "            frame.copy(), # 傳遞副本以避免修改原始幀\n",
        "            predictions_for_current_frame\n",
        "        )\n",
        "\n",
        "        # 將 OpenCV 的 BGR 格式轉換為 Matplotlib 的 RGB 格式\n",
        "        rendered_frames.append(cv2.cvtColor(rendered_frame, cv2.COLOR_BGR2RGB))\n",
        "        current_frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Finished rendering {len(rendered_frames)} frames.\")\n",
        "    return rendered_frames, fps # 同時返回幀列表和 FPS\n",
        "\n",
        "def play_video_from_frames(frames: list, fps: float = 30.0, output_filename: str = 'output_pose_video.mp4'):\n",
        "    \"\"\"\n",
        "    使用 Matplotlib 播放影片幀序列。在 Colab 環境中，將影片保存為 MP4 並嵌入顯示。\n",
        "\n",
        "    Args:\n",
        "        frames (list): 包含所有影片幀 (NumPy array) 的列表。\n",
        "        fps (float): 影片的幀率，用於計算播放間隔。\n",
        "        output_filename (str): 動畫將保存為指定文件名的 MP4 影片。\n",
        "    \"\"\"\n",
        "    if not frames:\n",
        "        print(\"No frames to play.\")\n",
        "        return\n",
        "\n",
        "    interval_ms = 1000 / fps if fps > 0 else 40 # 計算每幀間隔，預設40ms\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(frames[0].shape[1] / 100, frames[0].shape[0] / 100), dpi=100)\n",
        "    ax.axis('off')\n",
        "    img = ax.imshow(frames[0])\n",
        "\n",
        "    def update(frame_idx):\n",
        "        img.set_array(frames[frame_idx])\n",
        "        return [img]\n",
        "\n",
        "    ani = FuncAnimation(fig, update, frames=len(frames), interval=interval_ms, blit=True)\n",
        "\n",
        "    print(f\"Saving animation to {output_filename}...\")\n",
        "    try:\n",
        "        # 嘗試保存動畫。在 Colab 中，ffmpeg 通常已預裝並在 PATH 中。\n",
        "        # 'dpi' 參數可以調整輸出影片的解析度\n",
        "        ani.save(output_filename, writer='ffmpeg', fps=fps, dpi=200)\n",
        "        print(f\"Animation saved as {output_filename}\")\n",
        "\n",
        "        # 在 Colab 中嵌入並顯示影片\n",
        "        if os.path.exists(output_filename):\n",
        "            display(Video(output_filename, embed=True, html_attributes=\"controls autoplay loop\"))\n",
        "        else:\n",
        "            print(f\"Warning: Output video file '{output_filename}' not found after saving attempt.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving and displaying animation: {e}\")\n",
        "        print(\"Please ensure FFmpeg is installed and accessible (e.g., 'sudo apt-get install ffmpeg' on Linux systems, or it's often pre-installed in Colab).\")\n",
        "\n",
        "    # 關閉繪圖，釋放記憶體\n",
        "    plt.close(fig)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # --- 測試區塊 ---\n",
        "    # 這裡的 dummy_api_response 變數將直接使用您之前提供的 response.json() 內容\n",
        "    # 因為我無法直接執行您的 API 調用，請確保您在運行此腳本前，\n",
        "    # 已經將 response.json() 的實際結果賦值給 dummy_api_response。\n",
        "\n",
        "    # 請務必將此替換為您實際的 response.json() 內容！\n",
        "    dummy_api_response = response.json()\n",
        "\n",
        "    # 替換為您的實際影片路徑\n",
        "    video_file_path = '/content/pitch_0029.mp4' # 範例中的影片路徑\n",
        "\n",
        "    # 運行渲染和播放\n",
        "    print(f\"Attempting to render video: {video_file_path}\")\n",
        "    rendered_frames, fps = render_video_with_pose(video_file_path, dummy_api_response)\n",
        "\n",
        "    if rendered_frames:\n",
        "        print(\"Playing rendered video...\")\n",
        "        # 調用修改後的函數，並指定輸出檔案名\n",
        "        play_video_from_frames(rendered_frames, fps, output_filename='output_pose_video.mp4')\n",
        "    else:\n",
        "        print(\"No frames were rendered. Check video path and API response data.\")"
      ],
      "metadata": {
        "id": "S6h1aytrshvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VpBcOS6vtr9-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}